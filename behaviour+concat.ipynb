{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tifffile import imread\n",
    "from tifffile import imsave\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Used to consolidate the planes of FIJI calcium activity into a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_orig_df(file_path):\n",
    "    file_path = file_path\n",
    "    orig_df = pd.read_csv(file_path)\n",
    "    return orig_df\n",
    "\n",
    "def get_cols(orig_df):\n",
    "    numRois = int((orig_df.shape[1]-1)/4)\n",
    "    col_names = []\n",
    "    for i in range(1,numRois+1):\n",
    "        col_names.append('Mean'+str(i))\n",
    "    print(col_names)\n",
    "    return col_names\n",
    "\n",
    "def consolidate_concated():\n",
    "#     main_path = 'C:/Users/MICHAEL/Documents/Complete Analysis/'\n",
    "    main_path = 'D:/Michael D/Good PAG data/final roi sets and activity/Long stim/'\n",
    "    df_list = []\n",
    "    m = 3\n",
    "    n = 8\n",
    "    for i in range(m,n):\n",
    "        file_start = '1June22_fish1_rlnLZ'\n",
    "        file_end = 'RoiAct.csv'\n",
    "        file_path = main_path+file_start+str(i)+file_end\n",
    "        orig_df = get_orig_df(file_path)\n",
    "        col_names = get_cols(orig_df)\n",
    "        df = pd.read_csv(main_path+file_name, usecols=col_names)\n",
    "        df_list.append(df)\n",
    "    final_df = pd.concat(df_list, axis=1)\n",
    "    final_df.to_csv('1June22_fish1_rlnLRoiAllStim.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consol_files():\n",
    "#     main_path = 'C:/Users/MICHAEL/Documents/Complete Analysis/'\n",
    "#     main_path = 'D:/Michael D/Good PAG data/final roi sets and activity/split_final_files/allstim_files to avg/avg_files/'\n",
    "    main_path = 'C:/Users/Michael/Documents/Complete Analysis/Final Plotting Folder/'\n",
    "    end = '.csv'\n",
    "#     main_path = 'D:/Michael D/Good PAG data/Final Fig Data/Sensory stim/'\n",
    "    df1 = pd.read_csv(main_path+'1June22_fish3_penk_ContAllStimOMRavgs'+end, index_col=0)\n",
    "    df2 = pd.read_csv(main_path+'1June22_fish1_penk_ContAllStimOMRavgs'+end, index_col=0)\n",
    "#     df3 = pd.read_csv(main_path+'23Mar22_fish2_rln_ContAllStimOMRavgs'+end, index_col=0)\n",
    "#     df4 = pd.read_csv(main_path+'22June2_fish2G_penk_LeftPAG6avgs'+end, index_col=0)\n",
    "#     df5 = pd.read_csv(main_path+'20July22_fish3_new_penkLeftAllStimclose_norespavgs'+end, index_col=0)\n",
    "#     df6 = pd.read_csv(main_path+'25May22_fish2_new_penkRightAllStimclose_norespavgs'+end, index_col=0)\n",
    "#     df7 = pd.read_csv(main_path+'25May22_fish3_new_penkLeftAllStimclose_norespavgs'+end, index_col=0)\n",
    "    tot_df = pd.concat((df1, df2), axis=1)#, df3, df4df5, df6, df7, df8, df5\n",
    "    tot_df.to_csv('Final_OMRstim_penk_ContAllStim.csv')\n",
    "    print(tot_df.shape)\n",
    "    plt.plot(tot_df)\n",
    "    plt.show()\n",
    "\n",
    "consol_files()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1June22_fish1_2_rlnRightPAG6_listavgs\n",
    "# 2Mar22_fish3_rlnRightPAG6_listavgs\n",
    "# 9Mar22_fish1_2_rlnRightPAG6_listavgs\n",
    "# 17May22_fish2R_rln_RightPAG6_listavgs\n",
    "# 20July22_fish3_rln_rightPAG6_listavgs\n",
    "# 25May22_fish2_rlnRightPAG6_listavgs\n",
    "# 25May22_fish3R_rlnRightPAG6_listavgs\n",
    "# LLLRRLR\n",
    "\n",
    "# 1June22_fish1_penk2_LeftPAG6_listavgs    \n",
    "# 2Mar22_fish3_penkLeftPAG6_listavgs\n",
    "# 9Mar22_fish1_penk_LeftPAG6_listavgs\n",
    "# 20July22_fish3_penk_LeftPAG6_listavgs\n",
    "# 25May22_fish2_penk_LeftPAG6_listavgs\n",
    "# 25May22_fish3_penk_LeftPAG6_listavgs\n",
    "# LLLRLR\n",
    "\n",
    "#     df1 = pd.read_csv(main_path+'1June22_fish1_2_penkContPAG6_listavgs'+end, index_col=0)\n",
    "#     df2 = pd.read_csv(main_path+'2Mar22_fish3_penkContPAG6_listavgs'+end, index_col=0)\n",
    "#     df3 = pd.read_csv(main_path+'9Mar22_fish1_2_penkContPAG6_listavgs'+end, index_col=0)\n",
    "#     df4 = pd.read_csv(main_path+'17May22_fish2R_penk_ContPAG6_listavgs'+end, index_col=0)\n",
    "#     df5 = pd.read_csv(main_path+'20July22_fish3_penk_ContPAG6_listavgs'+end, index_col=0)\n",
    "#     df6 = pd.read_csv(main_path+'25May22_fish2_penkContPAG6_listavgs'+end, index_col=0)\n",
    "#     df7 = pd.read_csv(main_path+'25May22_fish3R_rlnContPAG6_listavgs'+end, index_col=0)\n",
    "consol_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#will need to do a little bit of changing this, it originally was just run this, run df1 cell, change to z2 run df2 cell, etc.\n",
    "# main_path = 'C:/Users/Michael/Documents/Complete Analysis/'\n",
    "# main_path = 'D:/Michael D/Good PAG data/final roi sets and activity/split_final_files/allstim_files to avg/roisets for allstim/'\n",
    "# main_path = 'D:/Michael D/Good PAG data/final roi sets and activity/PAG6/1June22_fish1/1June22_fish1_penk/'\n",
    "# main_path = 'D:/Michael D/Good PAG data/final roi sets and activity/split_final_files/holding ind files/'\n",
    "# main_path = 'D:/Michael D/Good PAG data/2Mar22/2Mar22_Fish3/2Mar22_properActivity/'\n",
    "main_path = 'D:/Michael D/Good PAG data/Tod Meetings/Nov10/OMR/'\n",
    "# main_path = 'C:/Users/Michael/Documents/Complete Analysis/Final Plotting Folder/'\n",
    "\n",
    "\n",
    "file = '1June22_fish3_penkRz7RoiAct.csv'\n",
    "file_name = main_path+file\n",
    "orig_df = get_orig_df(file_name)\n",
    "col_names = get_cols(orig_df)\n",
    "\n",
    "# 1June22_fish1_rlnLeft_NORESP\n",
    "# 1June22_fish3_rlnLeft_NORESP\n",
    "# 25May22_fish2_rlnRight_NORESP\n",
    "# 25May22_fish3_rlnLeft_NORESP\n",
    "# 17May22_fish2_rlnLeft_RESP\n",
    "# 9Mar22_fish1_rlnLeft_NORESP\n",
    "# 2Mar22_fish3_rlnRight_NORESP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = pd.read_csv(file_name, usecols=col_names)\n",
    "\n",
    "# df2 = pd.read_csv(file_name, usecols=col_names)\n",
    "\n",
    "# df3 = pd.read_csv(file_name, usecols=col_names)\n",
    "\n",
    "df4 = pd.read_csv(file_name, usecols=col_names)\n",
    "\n",
    "# df5 = pd.read_csv(file_name, usecols=col_names)\n",
    "\n",
    "# df6 = pd.read_csv(file_name, usecols=col_names)\n",
    "\n",
    "# df7 = pd.read_csv(file_name, usecols=col_names)\n",
    "\n",
    "# df8 = pd.read_csv(file_name, usecols=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_df = pd.concat((df1, df2, df3, df4), axis=1)#, df5, df6, df7, df8, df9, df10, df11), axis=1)\n",
    "# tot_df = pd.concat((df7, df8, df9, df10, df11, df12), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_df.to_csv('1June22_fish3_penk_IpsAllStim.csv')\n",
    "# 9Mar22_H2B_fish1_AGrlnz7LRoiAct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Find trials with behaviour\n",
    "## Taken from MBehaviour_analysis_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_path = 'D:/Michael D/Good PAG data/good_behaviours/PAG6_behaviours'\n",
    "main_path = 'C:/Users/MICHAEL/Documents/code/behaviour'\n",
    "\n",
    "source_dir = Path(main_path)\n",
    "files = source_dir.iterdir()\n",
    "tail_kin_files = []\n",
    "for item in files:\n",
    "    if 'tail-kinematics' in str(item):\n",
    "#     print(str(item).replace('\\\\','/'))\n",
    "        tail_kin_files.append(str(item).replace('\\\\','/'))\n",
    "\n",
    "def behaviour_check(open_window, close_window, trial):\n",
    "    test_file = pd.read_csv(trial)\n",
    "    tail_kin = test_file.loc[:,'Value.Amplitude']\n",
    "    \n",
    "    start_time = open_window*350\n",
    "    end_time = close_window*350\n",
    "    \n",
    "    \n",
    "    if len(tail_kin[:start_time].loc[abs(tail_kin)>20]) > 5 :\n",
    "        holder=0\n",
    "    elif len(tail_kin[end_time:].loc[abs(tail_kin)>20]) > 5 :\n",
    "        holder=0\n",
    "    elif len(tail_kin[start_time:end_time].loc[abs(tail_kin)>20]) > 5 :\n",
    "        #determines if there was activity in the set window, if yes returns 1 in holder, if no returns 0\n",
    "#         print('activity')\n",
    "        holder = 1\n",
    "    else:\n",
    "#         print('NR')\n",
    "        holder = 0\n",
    "    return holder\n",
    "\n",
    "#provides list of len (behaviour_trials) where 0 is no behaviour, 1 is bheaviour\n",
    "tot = []\n",
    "for i in tail_kin_files:\n",
    "    holder = behaviour_check(20,25, i)\n",
    "    tot.append(holder)\n",
    "print(tot)\n",
    "\n",
    "#prints number of trials with behaviour and trial names\n",
    "com = 0\n",
    "for i,j in zip(tot, tail_kin_files):\n",
    "    if i == 1:\n",
    "        print(str(j))\n",
    "        com +=1\n",
    "        \n",
    "print(com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_path = 'D:/Michael D/Good PAG data/good_behaviours/PAG6_behaviours'\n",
    "main_path = 'C:/Users/MICHAEL/Documents/code/behaviour'\n",
    "\n",
    "source_dir = Path(main_path)\n",
    "files = source_dir.iterdir()\n",
    "tail_kin_files = []\n",
    "for item in files:\n",
    "    if 'tail-kinematics' in str(item):\n",
    "#     print(str(item).replace('\\\\','/'))\n",
    "        tail_kin_files.append(str(item).replace('\\\\','/'))\n",
    "\n",
    "def behaviour_check(open_window, close_window, trial):\n",
    "    test_file = pd.read_csv(trial)\n",
    "    tail_kin = test_file.loc[:,'Value.Amplitude']\n",
    "    \n",
    "    start_time = open_window*350\n",
    "    end_time = close_window*350\n",
    "    exl_start = 25*350\n",
    "    exl_end = 35*350\n",
    "    \n",
    "    if len(tail_kin[exl_start:exl_end].loc[abs(tail_kin)>20]) > 5 :\n",
    "        holder=0\n",
    "    elif len(tail_kin[start_time:end_time].loc[abs(tail_kin)>20]) > 5 :\n",
    "        #determines if there was activity in the set window, if yes returns 1 in holder, if no returns 0\n",
    "#         print('activity')\n",
    "        holder = 1\n",
    "    else:\n",
    "#         print('NR')\n",
    "        holder = 0\n",
    "    return holder\n",
    "\n",
    "#provides list of len (behaviour_trials) where 0 is no behaviour, 1 is behaviour\n",
    "tot = []\n",
    "for i in tail_kin_files:\n",
    "    holder = behaviour_check(20,25, i)\n",
    "    tot.append(holder)\n",
    "print(tot)\n",
    "\n",
    "#prints number of trials with behaviour and trial names\n",
    "com = 0\n",
    "for i,j in zip(tot, tail_kin_files):\n",
    "    if i == 1:\n",
    "        print(str(j))\n",
    "        com +=1\n",
    "        \n",
    "print(com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#one cell to get tail angle files, analyze to determine which are responsive, and print\n",
    "\n",
    "# main_path = 'D:/Michael D/Good PAG data/25May22/25May22_behaviour/'\n",
    "# main_path = 'D:/Michael D/Good PAG data/1June22/2022-06-01'\n",
    "main_path = 'D:/Michael D/Good PAG data/good_behaviours/PAG6_behaviours'\n",
    "\n",
    "source_dir = Path(main_path)\n",
    "files = source_dir.iterdir()\n",
    "tail_kin_files = []\n",
    "for item in files:\n",
    "    if 'tail-kinematics' in str(item):\n",
    "#     print(str(item).replace('\\\\','/'))\n",
    "        tail_kin_files.append(str(item).replace('\\\\','/'))\n",
    "\n",
    "def behaviour_check(open_window, close_window, trial):\n",
    "    test_file = pd.read_csv(trial)\n",
    "    tail_kin = test_file.loc[:,'Value.Amplitude']\n",
    "    \n",
    "#     ex_start = \n",
    "#     ex_end = \n",
    "    \n",
    "    start_time = open_window*350\n",
    "    end_time = close_window*350\n",
    "    \n",
    "    if len(tail_kin[start_time:end_time].loc[abs(tail_kin)>20]) > 5 :\n",
    "        #determines if there was activity in the set window, if yes returns 1 in holder, if no returns 0\n",
    "#         print('activity')\n",
    "        holder = 1\n",
    "    else:\n",
    "#         print('NR')\n",
    "        holder = 0\n",
    "    return holder\n",
    "\n",
    "#provides list of len (behaviour_trials) where 0 is no behaviour, 1 is bheaviour\n",
    "tot = []\n",
    "for i in tail_kin_files:\n",
    "    holder = behaviour_check(25,30, i)\n",
    "    tot.append(holder)\n",
    "print(tot)\n",
    "\n",
    "#prints number of trials with behaviour and trial names\n",
    "com = 0\n",
    "for i,j in zip(tot, tail_kin_files):\n",
    "    if i == 1:\n",
    "        print(str(j))\n",
    "        com +=1\n",
    "        \n",
    "print(com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_path = 'D:/Michael D/Good PAG data/25May22/25May22_behaviour/'\n",
    "main_path = 'D:/Michael D/Good PAG data/20July22/2022-07-20'\n",
    "source_dir = Path(main_path)\n",
    "files = source_dir.iterdir()\n",
    "tail_kin_files = []\n",
    "for item in files:\n",
    "    if 'tail-kinematics' in str(item):\n",
    "#     print(str(item).replace('\\\\','/'))\n",
    "        tail_kin_files.append(str(item).replace('\\\\','/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get files\n",
    "# main_path = 'C:/Users/MICHAEL/Documents/code'\n",
    "main_path = 'D:/Michael D/Good PAG data/19July22/2022-07-19'\n",
    "source_dir = Path(main_path)\n",
    "files = source_dir.iterdir()\n",
    "tail_angles = []\n",
    "foo = 0\n",
    "for item in files:\n",
    "    if 'tail-kinematics' in str(item):\n",
    "        print('this file is in the folder')\n",
    "        print(item)\n",
    "        tail_kin_file = (str(item).replace('\\\\','/'))\n",
    "        test_file = pd.read_csv(tail_kin_file)\n",
    "        tail_kin = test_file.loc[:,'Value.Amplitude']\n",
    "        tail_angles.append(tail_kin)\n",
    "tail_df = pd.concat(tail_angles, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def behaviour_check(open_window, close_window, trial):\n",
    "    test_file = pd.read_csv(trial)\n",
    "    tail_kin = test_file.loc[:,'Value.Amplitude']\n",
    "    \n",
    "    start_time = open_window*350\n",
    "    end_time = close_window*350\n",
    "    \n",
    "    if len(tail_kin[start_time:end_time].loc[abs(tail_kin)>20]) > 5 :\n",
    "        #determines if there was activity in the set window, if yes returns 1 in holder, if no returns 0\n",
    "#         print('activity')\n",
    "        holder = 1\n",
    "    else:\n",
    "#         print('NR')\n",
    "        holder = 0\n",
    "    return holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#provides list of len (behaviour_trials) where 0 is no behaviour, 1 is bheaviour\n",
    "tot = []\n",
    "for i in tail_kin_files:\n",
    "    holder = behaviour_check(22,32, i)\n",
    "    tot.append(holder)\n",
    "print(tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prints number of trials with behaviour and trial names\n",
    "com = 0\n",
    "for i,j in zip(tot, tail_kin_files):\n",
    "    if i == 1:\n",
    "        print(str(j))\n",
    "        com +=1\n",
    "        \n",
    "print(com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behaviour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate behaviour trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_behaviour(main_path, behaviour_files, final_name):\n",
    "    tail_arr = []\n",
    "    for behav in behaviour_files:\n",
    "        orig_file = pd.read_csv((main_path+ str(behav)))\n",
    "        trial_angle = orig_file['Value.Amplitude']\n",
    "        tail_arr.append(trial_angle)\n",
    "    tot_df = pd.concat(tail_arr)\n",
    "    save_name = final_name + 'tail_angle.csv'\n",
    "    tot_df.to_csv(save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean_behaviour demo\n",
    "\n",
    "f1 = '6Apr22_H2Bfish1_PAG_1B_tail-kinematics.csv'\n",
    "f2 = '6Apr22_H2Bfish1_PAG_1C_tail-kinematics.csv'\n",
    "f3 = '6Apr22_H2Bfish1_PAG_1G_tail-kinematics.csv'\n",
    "f4 = '6Apr22_H2Bfish1_PAG_1K_tail-kinematics.csv'\n",
    "\n",
    "main_path = 'C:/Users/mmart/Desktop/tempFiles/'\n",
    "behaviour_files = [f1, f2, f3, f4]\n",
    "final_name = '6Apr22_H2Bfish1_BK'\n",
    "\n",
    "clean_behaviour(main_path, behaviour_files, final_name)\n",
    "\n",
    "# testdf = pd.read_csv('test_concat.csv')\n",
    "\n",
    "# plt.plot(testdf['Value.Amplitude'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##lots of half written codes to update my functions\n",
    "\n",
    "##shows what files I used\n",
    "\n",
    "fname = '6Apr22_fish1_h2b_RLNz3_mc_ABCROIAct.csv'\n",
    "tot= pd.read_csv(fname, index_col=0)\n",
    "\n",
    "##Use this to get the particular activity we are interested in\n",
    "ind_val = all_trials.index('B')\n",
    "\n",
    "totb = tot.iloc[136*ind_val:136*(ind_val+1)]\n",
    "plt.plot(totb)\n",
    "plt.show()\n",
    "\n",
    "##trying to recognize which trial in all_trials corresponds to what stim\n",
    "loom = 'AH'\n",
    "dim1 = 'BFG'\n",
    "dim2 = 'D'\n",
    "\n",
    "# loom = input('which trials had a loom: ')\n",
    "# dim1 = input('which trials had a dim1: ')\n",
    "# dim2 = input('which trials had a dim2: ')\n",
    "\n",
    "# ABDFGH\n",
    "stim_dict = {}\n",
    "loom_list = []\n",
    "j=0\n",
    "for i in all_trials:\n",
    "    print(i)\n",
    "    if i in loom:\n",
    "        print('loom stim', str(j), str(i))\n",
    "        if 'loom' in stim_dict.keys():\n",
    "            stim_dict['loom'] = stim_dict['loom'].append(tot.iloc[136*all_trials.index(i):136*(all_trials.index(i)+1)])\n",
    "            print('hello')\n",
    "            plt.plot(stim_dict['loom'])\n",
    "            plt.show()\n",
    "            hold = input('test2')\n",
    "            loom_list.append(tot.iloc[136*all_trials.index(i):136*(all_trials.index(i)+1)].reset_index().drop('index', axis=1))\n",
    "        else:\n",
    "            stim_dict['loom'] = tot.iloc[136*all_trials.index(i):136*(all_trials.index(i)+1)]\n",
    "            plt.plot(stim_dict['loom'])\n",
    "            plt.show()\n",
    "            hold = input('test1')\n",
    "            loom_list.append(tot.iloc[136*all_trials.index(i):136*(all_trials.index(i)+1)].reset_index().drop('index', axis=1))\n",
    "    elif i in dim1:\n",
    "        print('dim1 stim', str(j), str(i))\n",
    "    elif i in dim2:\n",
    "        print('dim2 stim', str(j), str(i))\n",
    "    j +=1\n",
    "    \n",
    "##as it is, axis=1 combines all the trials appropriately, but I want to try to figure out how to make it work where I\n",
    "##concatenate them timewise as well\n",
    "loom2 = pd.concat(loom_list, axis=1)\n",
    "loom3 = pd.concat(loom_list, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate neuron activity files that have already been analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is exclusively to act as a reminder to get the trial names, keep everything organized\n",
    "def set_trials():\n",
    "    all_trials = 'ABC'\n",
    "    pag6 = 'AB'\n",
    "    dim = 'C'\n",
    "    \n",
    "    return all_trials, pag6, dim\n",
    "\n",
    "all_trials, pag6, dim = set_trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##First things first I need to be able to concatenate any files I need (L+R, R vs NR, diff stim, different days)\n",
    "#determine what type of concat I am doing\n",
    "#load files\n",
    "#concat appropriately\n",
    "#save new group\n",
    "\n",
    "##Will need to be able to split all files, but currently can work with what I've got\n",
    "def complete_concat():\n",
    "    concat_type = input(\"What type of input are you choosing? L+R[1], Resp/NR[2], diff stim [3], diff days [4], all same [5], already analyzed[6] multiple[0]\")\n",
    "\n",
    "    \n",
    "def concat_same_stim():\n",
    "    \n",
    "complete_concat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_pre_analyzed():\n",
    "    #code to concatenate the neuronal activity of trials that I have already analyzed and split based on response no response\n",
    "    #or stim trial, or whatever, and it creates and averge file\n",
    "    #hard coded a bunch of this to make it quicker\n",
    "    \n",
    "    sep_type = 1#int(input('separated by stim[1], response[2]'))\n",
    "    file_base = '9Mar22_H2B_fish1_PAG_rlnRoiActRightNORESPA'\n",
    "    diff_stims = ['CEJKL']\n",
    "    tot_list = []\n",
    "    stim_avg_list = []\n",
    "    if sep_type == 1:\n",
    "        #load up different groups of stimuli (ABC, DEF, etc.) to separate them into individual trials to average them\n",
    "        for stim in diff_stims:\n",
    "            #loads the specific stimuli\n",
    "            stim_df = pd.read_csv(('9Mar22_H2B_fish1_PAG_rlnRoiActRightNORESPA.csv'), index_col=0)\n",
    "            \n",
    "            len_trial = int(stim_df.shape[0]/len(stim))\n",
    "            \n",
    "            trial_df_list = []\n",
    "            \n",
    "            for trial in range(len(stim)):\n",
    "                if trial == 0:\n",
    "                    stim_avg = stim_df.iloc[len_trial*trial:len_trial*(trial+1)].reset_index().drop('index', axis=1)\n",
    "                else:\n",
    "                    stim_avg = stim_avg.add(stim_df.iloc[len_trial*trial:len_trial*(trial+1)].reset_index().drop('index', axis=1))\n",
    "                    \n",
    "            stim_avg_list.append(stim_avg/len(stim)) \n",
    "            \n",
    "            \n",
    "    \n",
    "#             print('tot_stim.shape is', tot_stim.shape)\n",
    "            \n",
    "        \n",
    "    else:\n",
    "#         response_list = ['ABDF', 'GHEF']\n",
    "#         file_base = '9Mar22_'\n",
    "#         for beh in (response_list):\n",
    "            \n",
    "#             beh_df = pd.read_csv((file_base+beh+'.csv'), index_col=0)\n",
    "#             len_trial = int(beh_df.shape[0]/len(beh))\n",
    "            \n",
    "#             for trial in range(len(beh)):\n",
    "#                 if trial == 0:\n",
    "#                     beh_avg = beh_df.iloc[len_trial*trial:len_trial*(trial+1)].reset_index().drop('index', axis=1)\n",
    "#                 else:\n",
    "#                     beh_avg = beh_avg.add(beh_df.iloc[len_trial*trial:len_trial*(trial+1)].reset_index().drop('index', axis=1))\n",
    "            \n",
    "        \n",
    "        print('response')\n",
    "#     tot_stim = pd.concat(stim_avg_list, axis=0, ignore_index=True)\n",
    "    tot_stim = stim_avg_list[0]\n",
    "    tot_stim.to_csv((file_base+'AllStim.csv'))\n",
    "    return stim_avg_list, tot_stim\n",
    "\n",
    "# stim_avg_list, tot_stim = concat_pre_analyzed()\n",
    "# plt.plot(tot_stim)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_avg_list, tot_stim = concat_pre_analyzed()\n",
    "plt.plot(tot_stim)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to split tif files and concatenate them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_concat(trials, file_stem, num_planes):\n",
    "    '''Concatenates all the trials we use and saves them as individual z planes'''\n",
    "    for z in range(0,num_planes):\n",
    "        coll_arr = []\n",
    "        for j in trials:\n",
    "            trial_arr = imread(file_stem+j+'_00001.tif')\n",
    "            clean_plane = trial_arr[z::11]\n",
    "        #     print(type(clean_plane))\n",
    "        #     print(clean_plane.shape)\n",
    "            coll_arr.append(clean_plane)\n",
    "        concat_arr = np.array(coll_arr)\n",
    "        print(concat_arr.shape)\n",
    "#         print(concat_arr[0].shape)\n",
    "#         print(concat_arr[4].shape)\n",
    "        imsave((file_stem+'concatZ'+str(z)+'.tif'),concat_arr)\n",
    "\n",
    "clean_and_concat(trials = 'LMNP', num_planes = 10, file_stem = '4May22_PAG_Fish2_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to split ROI activity into various subgroups\n",
    "### Used when I have analyzed the activity of a plane which I had concatenated many (potentially all) the trials together before analyzing in FIJI and I need to split them into response no response or stim or whatever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_pre_analyzed():\n",
    "    #code to concatenate the neuronal activity of trials that I have already analyzed and split based on response no response\n",
    "    #or stim trial, or whatever, and it creates and averge file\n",
    "    #hard coded a bunch of this to make it quicker\n",
    "    #final output is an average of the activity of one neuron during any particular trial\n",
    "\n",
    "    sep_type = 1#int(input('separated by stim[1], response[2]'))\n",
    "    file_base = '9Mar22_H2B_fish1_PAG_rRLN_mc_'\n",
    "    diff_stims = ['ABDFGH', 'CEJKL']\n",
    "    tot_list = []\n",
    "    stim_avg_list = []\n",
    "    if sep_type == 1:\n",
    "        #load up different groups of stimuli (ABC, DEF, etc.) to separate them into individual trials to average them\n",
    "        for stim in diff_stims:\n",
    "            #loads the specific stimuli\n",
    "            stim_df = pd.read_csv((file_base+str(stim)+'ROIAct.csv'), index_col=0)\n",
    "            \n",
    "            len_trial = int(stim_df.shape[0]/len(stim))\n",
    "            \n",
    "            trial_df_list = []\n",
    "            \n",
    "            for trial in range(len(stim)):\n",
    "                if trial == 0:\n",
    "                    stim_avg = stim_df.iloc[len_trial*trial:len_trial*(trial+1)].reset_index().drop('index', axis=1)\n",
    "                else:\n",
    "                    stim_avg = stim_avg.add(stim_df.iloc[len_trial*trial:len_trial*(trial+1)].reset_index().drop('index', axis=1))\n",
    "                    \n",
    "            stim_avg_list.append(stim_avg/len(stim)) \n",
    "            \n",
    "            \n",
    "    \n",
    "#             print('tot_stim.shape is', tot_stim.shape)\n",
    "            \n",
    "        \n",
    "    else:\n",
    "#         response_list = ['ABDF', 'GHEF']\n",
    "#         file_base = '9Mar22_'\n",
    "#         for beh in (response_list):\n",
    "            \n",
    "#             beh_df = pd.read_csv((file_base+beh+'.csv'), index_col=0)\n",
    "#             len_trial = int(beh_df.shape[0]/len(beh))\n",
    "            \n",
    "#             for trial in range(len(beh)):\n",
    "#                 if trial == 0:\n",
    "#                     beh_avg = beh_df.iloc[len_trial*trial:len_trial*(trial+1)].reset_index().drop('index', axis=1)\n",
    "#                 else:\n",
    "#                     beh_avg = beh_avg.add(beh_df.iloc[len_trial*trial:len_trial*(trial+1)].reset_index().drop('index', axis=1))\n",
    "            \n",
    "        \n",
    "        print('response')\n",
    "    tot_stim = pd.concat(stim_avg_list, axis=0, ignore_index=True)\n",
    "    tot_stim.to_csv((file_base+'AllStim.csv'))\n",
    "    return stim_avg_list, tot_stim\n",
    "\n",
    "# stim_avg_list, tot_stim = concat_pre_analyzed()\n",
    "# plt.plot(tot_stim)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_arr = pd.read_csv(('9Mar22_H2B_fish1_PAG_rlnRoiActRightRESPA.csv'), index_col=0)\n",
    "tot_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_resp_splitter():\n",
    "    #different end product from concat_pre_analyzed because this gives activity of all the trials of a neuron based \n",
    "    fname = '2Mar22_fish3_rlnRightAllStim'\n",
    "    tot_arr = pd.read_csv((fname+'.csv'), index_col=0)\n",
    "    trial_list = 'ABCDEFGHJ'\n",
    "    resp_trials = 'ABDEFGHJ'\n",
    "    noresp_trials = 'C'\n",
    "    ind_trial_length = int(tot_arr.shape[0]/len(trial_list))\n",
    "    resp_act = []\n",
    "    noresp_act = []\n",
    "    \n",
    "    for i in range(len(trial_list)):\n",
    "        trial = trial_list[i]\n",
    "        if trial in resp_trials:\n",
    "            resp_act.append(tot_arr.iloc[(ind_trial_length*int(trial_list.index(trial))):(ind_trial_length*(int(trial_list.index(trial))+1))].reset_index().drop('index', axis=1))\n",
    "            x = tot_arr.iloc[(ind_trial_length*int(trial_list.index(trial))):(ind_trial_length*(int(trial_list.index(trial))+1))].reset_index().drop('index', axis=1)\n",
    "            print(int(trial_list.index(trial)))\n",
    "            print('The trial is', trial)\n",
    "\n",
    "        elif trial in noresp_trials:\n",
    "            noresp_act.append(tot_arr.iloc[(ind_trial_length*int(trial_list.index(trial))):(ind_trial_length*(int(trial_list.index(trial))+1))].reset_index().drop('index', axis=1))\n",
    "        else:\n",
    "            print('there must be a mistake, you are on trial '+ trial)\n",
    "    print('the shape of rest_act is', len(resp_act))\n",
    "    print('the shape of rest_act[0] is', str(resp_act[0].shape))\n",
    "    \n",
    "    resp_arr = pd.concat(resp_act, axis=0, ignore_index=True)\n",
    "    print(resp_arr.shape)\n",
    "    noresp_arr = pd.concat(noresp_act, axis=0, ignore_index=True)\n",
    "    return resp_arr, noresp_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def resp_splitter():\n",
    "    #splits a total csv into two conditions and concatenates them end to end so they're 136*x in length so I can have lindim or\n",
    "    #pag6 or something, then I need to average them in a different function.\n",
    "    fname = '1June22_fish1_rln_ContAllStim'\n",
    "    tot_arr = pd.read_csv((fname+'.csv'), index_col=0)\n",
    "    trial_list = 'ABCDEFGHJKLM'\n",
    "    resp_trials = 'LM'\n",
    "    noresp_trials = 'AB'\n",
    "    ind_trial_length = int(tot_arr.shape[0]/len(trial_list))\n",
    "    resp_act = []\n",
    "    noresp_act = []\n",
    "    \n",
    "    for i in range(len(trial_list)):\n",
    "        trial = trial_list[i]\n",
    "        if trial in resp_trials:\n",
    "\n",
    "            resp_act.append(tot_arr.iloc[(ind_trial_length*int(trial_list.index(trial))):(ind_trial_length*(int(trial_list.index(trial))+1))].reset_index().drop('index', axis=1))\n",
    "            x = tot_arr.iloc[(ind_trial_length*int(trial_list.index(trial))):(ind_trial_length*(int(trial_list.index(trial))+1))].reset_index().drop('index', axis=1)\n",
    "            print(int(trial_list.index(trial)))\n",
    "            print('The trial in resp is', trial)\n",
    "#             print(x.shape)\n",
    "#             print(len(resp_act))\n",
    "        elif trial in noresp_trials:\n",
    "            print('The trial in noresp is', trial)\n",
    "            noresp_act.append(tot_arr.iloc[(ind_trial_length*int(trial_list.index(trial))):(ind_trial_length*(int(trial_list.index(trial))+1))].reset_index().drop('index', axis=1))\n",
    "        else:\n",
    "            print('there must be a mistake, you are on trial '+ trial)\n",
    "    print('the shape of rest_act is', len(resp_act))\n",
    "    print('the shape of rest_act[0] is', str(resp_act[0].shape))\n",
    "    \n",
    "    resp_arr = pd.concat(resp_act, ignore_index=True)\n",
    "    print(resp_arr.shape)\n",
    "    noresp_arr = pd.concat(noresp_act, ignore_index=True)\n",
    "    return resp_arr, noresp_arr\n",
    "# resp_arr, noresp_arr = resp_splitter()\n",
    "\n",
    "resp_arr, noresp_arr = resp_splitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_arr.to_csv(('7June22_fish3_rln_LeftPAG6.csv'))# 1June22_fish1_rlnRRoiAllStim\n",
    "noresp_arr.to_csv(('7June22_fish3_rln_LeftLindim.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resp_arr, noresp_arr = resp_splitter()\n",
    "# resp_arr = resp_splitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(resp_arr)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_list = 'ABCDEFGHJK'\n",
    "\n",
    "pag6 = 'ADH'\n",
    "dim2 = 'J'\n",
    "dim3 = 'BK'\n",
    "dim4 = 'FG'\n",
    "wf = 'E'\n",
    "bf = 'C'\n",
    "# div_list = [pag6, dim2, dim3, dim4, wf, bg]\n",
    "div_list = [pag6, dim3]\n",
    "testarr = pd.read_csv(('17May22_fish2R_rlnRRoiAct.csv'), index_col=0)\n",
    "testarr.shape[0]/len(trial_list)\n",
    "# for i in pag6:\n",
    "#     print(trial_list.index(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(testarr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_averager():\n",
    "    trial_list = 'ABC'\n",
    "\n",
    "#     pag6 = 'ADH'\n",
    "#     dim2 = 'J'\n",
    "#     dim3 = 'BK'\n",
    "#     dim4 = 'FG'\n",
    "#     wf = 'E'\n",
    "#     bf = 'C'\n",
    "    \n",
    "    resp = 'ABC'\n",
    "    noresp = 'BCDHJK'\n",
    "    cond_list = [resp]#, noresp]\n",
    "#     cond_list = [pag6, dim3, dim4, dim2, wf, bf]\n",
    "    \n",
    "    \n",
    "    \n",
    "    tot_arr = pd.read_csv(('23Mar22_fish2_penk_WFRightAllStim.csv'), index_col=0)\n",
    "    ind_trial_length = int(tot_arr.shape[0]/len(trial_list))\n",
    "    \n",
    "    cond_avg_list = []\n",
    "    \n",
    "    for cond in cond_list:\n",
    "        \n",
    "        #Going to be ADH for example\n",
    "\n",
    "        for trial in cond:\n",
    "            #going to be A or D or H from cond\n",
    "            if cond.index(trial)==0:\n",
    "                complete_cond_avg = tot_arr.iloc[(ind_trial_length*int(trial_list.index(trial))):(ind_trial_length*(int(trial_list.index(trial))+1))].reset_index().drop('index', axis=1)\n",
    "            else:\n",
    "                complete_cond_avg = complete_cond_avg.add(tot_arr.iloc[(ind_trial_length*int(trial_list.index(trial))):(ind_trial_length*(int(trial_list.index(trial))+1))].reset_index().drop('index', axis=1))\n",
    "            \n",
    "        cond_avg_list.append(complete_cond_avg/len(cond))\n",
    "            \n",
    "    tot_stim = pd.concat(cond_avg_list, axis=0, ignore_index=True)\n",
    "    tot_stim.to_csv(('23Mar22_fish2_penk_WFRightAllStim'+'AllStim.csv'))\n",
    "    return tot_stim\n",
    "\n",
    "                                                                                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_list = total_averager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cond_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trial_list = 'ABCDEFGH'\n",
    "dim = 'ABF'\n",
    "pag6 = 'CEG'\n",
    "pag9 = 'DH'\n",
    "# for i in range(len(trial_list)):\n",
    "#     if trial_list[i] in dim:\n",
    "#         print('dim')\n",
    "#     elif trial_list[i] in pag6:\n",
    "#         print('pag6')\n",
    "#     elif trial_list[i] in pag9:\n",
    "#         print('pag9')\n",
    "#     print(i)\n",
    "#     print(trial_list[i])\n",
    "\n",
    "\n",
    "trial_list = 'ABCDEFGHJK'\n",
    "\n",
    "pag6 = 'ADH'\n",
    "dim2 = 'J'\n",
    "dim3 = 'BK'\n",
    "dim4 = 'FG'\n",
    "wf = 'E'\n",
    "bf = 'C'\n",
    "cond_list = [pag6, dim3]\n",
    "tot_arr = pd.read_csv(('4May22_fish2_rlnRRoiAct.csv'), index_col=0)\n",
    "ind_trial_length = tot_arr.shape[0]/len(trial_list)\n",
    "\n",
    "cond_avg_list = []\n",
    "\n",
    "for cond in cond_list:\n",
    "\n",
    "    #Going to be ADH for example\n",
    "\n",
    "    for trial in cond:\n",
    "        if cond.index(trial)==0:\n",
    "            print(trial)\n",
    "            print(ind_trial_length*int(trial_list.index(trial)))\n",
    "            print(ind_trial_length*(int(trial_list.index(trial))+1))\n",
    "        else:\n",
    "            print(trial)\n",
    "            print(ind_trial_length*int(trial_list.index(trial)))\n",
    "            print(ind_trial_length*(int(trial_list.index(trial))+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMAGE plotting for ROI planning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tif_file = '7June22_fish2L_mcActAnat.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_mc = imread(tif_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_mc[10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(tot_mc[1], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average every trial for a neuron and save csv of the averaged neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_averager():\n",
    "    \n",
    "#     main_path = 'D:/Michael D/Good PAG data/final roi sets and activity/sensory stim/Sept15/'\n",
    "#     main_path = 'D:/Michael D/Good PAG data/final roi sets and activity/split_final_files/allstim_files to avg/'\n",
    "#     main_path = 'D:/Michael D/Good PAG data/final roi sets and activity/split_final_files/allstim_files to avg/stim_files/'\n",
    "#     file_name = '22June22_fish2_A_penkLeft'\n",
    "    main_path = 'C:/Users/Michael/Documents/Complete Analysis/Final Plotting Folder/'\n",
    "    file_name = '1June22_fish1_penk_ContAllStim'\n",
    "    trial_list = 'ABCDEFGHJKLM'\n",
    "\n",
    "    all_trials = 'ABCDEFGHJKLM'\n",
    "#     close_resp = 'ACG'\n",
    "#     close_noresp = 'BDEFHJ'\n",
    "#     big_resp = 'ACGHJ'\n",
    "#     big_noresp = 'BDEF'\n",
    "#     PAG6_list =  'CD'\n",
    "\n",
    "#     WFBF = 'EF'\n",
    "    OMR = 'LM'    \n",
    "#     PAG9 = 'AD'\n",
    "#     PAG13 = 'BC'\n",
    "#     PAG14 = 'EF'\n",
    "#     cond_list = [noresp ,resp]\n",
    "    \n",
    "#     cond_list = [pag6, dim3, dim4, dim2, wf, bf]\n",
    "    avg_list = [OMR]#, PAG6_list, WFBF]\n",
    "    avg_name_list = ['OMR']#, 'PAG6_list', 'WFBF']\n",
    "    \n",
    "#     avg_list = [all_trials, close_resp, close_noresp, big_resp, big_noresp]#]\n",
    "#     avg_name_list = ['all_trials', 'close_resp', 'close_noresp', 'big_resp', 'big_noresp']#]\n",
    "\n",
    "#     avg_list = [PAG13, PAG9]#, PAG14]\n",
    "#     avg_name_list = ['PAG13', 'PAG9']#, 'PAG14']\n",
    "\n",
    "    \n",
    "    tot_arr = pd.read_csv((main_path+file_name+'.csv'), index_col=0)\n",
    "    ind_trial_length = int(tot_arr.shape[0]/len(trial_list))\n",
    "    \n",
    "    for group, group_name in zip(avg_list, avg_name_list):\n",
    "        avg_arr = []\n",
    "        for trial in group:\n",
    "            trial_f = tot_arr.iloc[(ind_trial_length*int(trial_list.index(trial))):(ind_trial_length*(int(trial_list.index(trial))+1))].reset_index().drop('index', axis=1)\n",
    "            avg_arr.append(trial_f)\n",
    "        if len(group) == 1:\n",
    "            groupdf =  tot_arr.iloc[(ind_trial_length*int(trial_list.index(trial))):(ind_trial_length*(int(trial_list.index(trial))+1))].reset_index().drop('index', axis=1)\n",
    "            groupdf.to_csv(file_name+group_name+'avgs.csv')\n",
    "            print(groupdf.shape)\n",
    "        else:\n",
    "            groupdf = pd.concat(avg_arr).mean(level=0)\n",
    "            print(groupdf.shape)\n",
    "            groupdf.to_csv(file_name+group_name+'avgs.csv')\n",
    "        \n",
    "    return groupdf\n",
    "        \n",
    "groupdf = general_averager()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_behaviour_func():\n",
    "    main_path = 'C:/Users/Michael/Documents/Complete Analysis/pag6behaviour'\n",
    "    file_names = get_all_trials(main_path)\n",
    "    tot_starts = []\n",
    "    for fname in file_names:\n",
    "        fstarts = get_starts(fname)\n",
    "        tot_starts.extend(fstarts)\n",
    "    return tot_starts\n",
    "\n",
    "def get_all_trials(main_path):\n",
    "    source_dir = Path(main_path)\n",
    "    files = source_dir.iterdir()\n",
    "    tail_kin_files = []\n",
    "    for item in files:\n",
    "    #     print(str(item).replace('\\\\','/'))\n",
    "        if str(item)[-5:] == 's.csv':\n",
    "            tail_kin_files.append(str(item).replace('\\\\','/'))\n",
    "    return tail_kin_files\n",
    "        \n",
    "def get_starts(fname):\n",
    "    df = pd.read_csv(fname)\n",
    "    df1=df['Value.Instance'].where(df['Value.Instance']==False, 1)\n",
    "    df2=df1.where(df1==True,0)\n",
    "    changes = df2[df2.diff()!=0].index.tolist()\n",
    "    starts=changes[1::2]\n",
    "#     starts = np.zeros(len(df2))\n",
    "#     for i in changes[1::2]:\n",
    "#         starts[i]=1\n",
    "        \n",
    "    return starts\n",
    "\n",
    "tot_starts=all_behaviour_func()\n",
    "# # ax=plt.subplot(111)\n",
    "# # plt.hist(tot_starts, bins=50, alpha=0.7)\n",
    "# # ax.spines['right'].set_visible(False)\n",
    "# # ax.spines['top'].set_visible(False)\n",
    "# # ax.set_xticks(np.linspace(0,17500,5))\n",
    "# # ax.set_xticklabels(np.linspace(0,17500,5)/350)\n",
    "# # plt.show()\n",
    "# # plt.savefig('totbehaviourhist.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_path = 'C:/Users/MICHAEL/Documents/code/behaviour'\n",
    "# main_path = 'C:/Users/Michael/Documents/Complete Analysis/tail_angle_files'\n",
    "main_path = 'C:/Users/Michael/Documents/Complete Analysis/pag6behaviour'\n",
    "\n",
    "source_dir = Path(main_path)\n",
    "files = source_dir.iterdir()\n",
    "tail_kin_files = []\n",
    "for item in files:\n",
    "    if 'tail-kinematics' in str(item):\n",
    "#     print(str(item).replace('\\\\','/'))\n",
    "        tail_kin_files.append(str(item).replace('\\\\','/'))\n",
    "    \n",
    "def get_all_trials(main_path):\n",
    "    source_dir = Path(main_path)\n",
    "    files = source_dir.iterdir()\n",
    "    tail_kin_files = []\n",
    "    for item in files:\n",
    "    #     print(str(item).replace('\\\\','/'))\n",
    "        if str(item)[-5:] == 's.csv':\n",
    "            tail_kin_files.append(str(item).replace('\\\\','/'))\n",
    "    return tail_kin_files\n",
    "\n",
    "def behaviour_check(open_window, close_window, trial):\n",
    "    test_file = pd.read_csv(trial)\n",
    "    tail_kin = test_file.loc[:,'Value.Amplitude']\n",
    "    \n",
    "    start_time = open_window*350\n",
    "    end_time = close_window*350\n",
    "    exl_start = 25*350\n",
    "    exl_end = 35*350\n",
    "\n",
    "#     if len(tail_kin[:start_time].loc[abs(tail_kin)>20]) > 5 :\n",
    "#         holder=0\n",
    "#     if len(tail_kin[exl_start:exl_end].loc[abs(tail_kin)>20]) > 5 :\n",
    "#         holder=0\n",
    "    if len(tail_kin[start_time:end_time].loc[abs(tail_kin)>10]) > 5 :\n",
    "        #determines if there was activity in the set window, if yes returns 1 in holder, if no returns 0\n",
    "#         print('activity')\n",
    "        holder = 1\n",
    "    else:\n",
    "#         print('NR')\n",
    "        holder = 0\n",
    "    return holder\n",
    "\n",
    "#provides list of len (behaviour_trials) where 0 is no behaviour, 1 is bheaviour\n",
    "tot = []\n",
    "for i in tail_kin_files:\n",
    "    holder = behaviour_check(20,25, i)\n",
    "    tot.append(holder)\n",
    "\n",
    "\n",
    "def all_behaviour_func():\n",
    "    main_path = 'C:/Users/Michael/Documents/Complete Analysis/pag6behaviour'\n",
    "    file_names = get_all_trials(main_path)\n",
    "    tot_starts = []\n",
    "    \n",
    "    for i,j in zip(tot, tail_kin_files):\n",
    "        if i == 1:\n",
    "            fstarts = get_starts(j)\n",
    "            tot_starts.extend(fstarts)\n",
    "    \n",
    "    return tot_starts\n",
    "\n",
    "        \n",
    "def get_starts(fname):\n",
    "    df = pd.read_csv(fname)\n",
    "    df1=df['Value.Instance'].where(df['Value.Instance']==False, 1)\n",
    "    df2=df1.where(df1==True,0)\n",
    "    changes = df2[df2.diff()!=0].index.tolist()\n",
    "    starts=changes[1::2]\n",
    "#     starts = np.zeros(len(df2))\n",
    "#     for i in changes[1::2]:\n",
    "#         starts[i]=1\n",
    "        \n",
    "    return starts\n",
    "\n",
    "tot_starts=all_behaviour_func()\n",
    "newstarts1 = [i for i in tot_starts if i>1750]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newstarts = [i for i in tot_starts if i>1750]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "fig.set_dpi(300)\n",
    "# newstarts3=newstarts+newstarts1\n",
    "ax=plt.subplot(211)\n",
    "# xbins = np.linspace(1750,17500,46)\n",
    "xbins = np.linspace(1745,17450,46)\n",
    "plt.hist(newstarts1, bins=xbins, alpha=0.7, color='gray')\n",
    "plt.hist(newstarts, bins=xbins, alpha=0.7, color='orange')\n",
    "plt.ylim(0,30)\n",
    "\n",
    "# plt.hist(newstarts3, bins=45, alpha=0.2, color='g')\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "# ax.set_xlim(min(newstarts), max(newstarts))\n",
    "xpos = [1750, 5250, 8750, 12250, 15750]\n",
    "# xpos = [1745, 5235, 8725, 12215, 15705]\n",
    "ax.set_xticks(xpos)\n",
    "ax.set_xticklabels((np.linspace(0,15750,5)/350)+5)\n",
    "# ax.set_yticklabels(ylabels, fontname=\"Arial\")\n",
    "xlab = ['0', '10', '20', '30', '40']\n",
    "ax.set_xticklabels(xlab, fontname=\"Arial\")\n",
    "\n",
    "# ax.set_xticklabels(xlab)\n",
    "\n",
    "# plt.show()\n",
    "plt.savefig('totclippedbehaviourtesttestE.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## comprehensive for creating R/NR for different windows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get behaviour in window of interest - done\n",
    "# select neuronal activity trials of interest based on behaviour -done\n",
    "# make averages for R/NR\n",
    "# save files\n",
    "\n",
    "# inputs:\n",
    "#     behaviour files\n",
    "#     neuronal files\n",
    "#     trial names\n",
    "    \n",
    "# main paths:\n",
    "#     behaviour path\n",
    "#     activity path\n",
    "    \n",
    "# preset data:\n",
    "#     trial names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates dict to cycle through animals\n",
    "Mar2_f3 = ['A', 'B', 'C', 'D', 'E' ,'F', 'G', 'H', 'J']#, 'K', 'L', 'M', 'N']\n",
    "mar9_f1 = ['A', 'B', 'C', 'D', 'E' ,'F', 'G', 'H', 'J', 'K', 'L']#, 'M', 'N']\n",
    "May17_f2 = ['A', 'B', 'C', 'D', 'E' ,'F', 'G', 'H', 'J', 'K']#, 'L', 'M', 'N']\n",
    "may25_f2 = ['A', 'B', 'C', 'D', 'E' ,'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N']\n",
    "may25_f3 = ['A', 'B', 'C', 'D', 'E' ,'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N']\n",
    "June1_f1 = ['A', 'B', 'C', 'D', 'E' ,'F', 'G', 'H', 'J', 'K', 'L', 'M']#, 'N']\n",
    "July20_f3 = ['A', 'B', 'C', 'D', 'E' ,'F', 'G', 'H', 'J']#, 'K', 'L', 'M', 'N']\n",
    "\n",
    "\n",
    "\n",
    "neuro_trial_dict = {'9Mar22_fish1': mar9_f1, '25May22_fish2': may25_f2, '25May22_fish3': may25_f3, \n",
    "                   '2Mar22_fish3': Mar2_f3, '17May22_fish2': May17_f2, '1Jun22_fish1': June1_f1, '20July22_fish3': July20_f3}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = 'D:/Michael D/Good PAG data/good_behaviours/PAG6_behaviours'\n",
    "\n",
    "source_dir = Path(main_path)\n",
    "files = source_dir.iterdir()\n",
    "tail_kin_files = []\n",
    "for item in files:\n",
    "    if 'tail-kinematics' in str(item):\n",
    "#     print(str(item).replace('\\\\','/'))\n",
    "        tail_kin_files.append(str(item).replace('\\\\','/'))\n",
    "\n",
    "def behaviour_check(open_window, close_window, trial):\n",
    "    test_file = pd.read_csv(trial)\n",
    "    tail_kin = test_file.loc[:,'Value.Amplitude']\n",
    "    \n",
    "    start_time = open_window*350\n",
    "    end_time = close_window*350\n",
    "    \n",
    "    \n",
    "#     if len(tail_kin[:start_time].loc[abs(tail_kin)>20]) > 5 :\n",
    "#         holder=0\n",
    "#     elif len(tail_kin[end_time:].loc[abs(tail_kin)>20]) > 5 :\n",
    "#         holder=0\n",
    "    if len(tail_kin[start_time:end_time].loc[abs(tail_kin)>20]) > 5 :\n",
    "        #determines if there was activity in the set window, if yes returns 1 in holder, if no returns 0\n",
    "#         print('activity')\n",
    "        holder = 1\n",
    "    else:\n",
    "#         print('NR')\n",
    "        holder = 0\n",
    "    return holder\n",
    "\n",
    "#provides list of len (behaviour_trials) where 0 is no behaviour, 1 is bheaviour\n",
    "tot = []\n",
    "for i in tail_kin_files:\n",
    "    holder = behaviour_check(20,37, i)\n",
    "    tot.append(holder)\n",
    "print(tot)\n",
    "\n",
    "#prints number of trials with behaviour and trial names\n",
    "com = 0\n",
    "h1 = []\n",
    "for i,j in zip(tot, tail_kin_files):\n",
    "    start = 59\n",
    "    if 'DATE' in j:\n",
    "        start+=30\n",
    "    if i == 1:\n",
    "        h1.append(j[start:-20])\n",
    "        com +=1\n",
    "        \n",
    "print(com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consol_files():\n",
    "#     main_path = 'C:/Users/MICHAEL/Documents/Complete Analysis/'\n",
    "#     main_path = 'D:/Michael D/Good PAG data/final roi sets and activity/split_final_files/allstim_files to avg/avg_files/'\n",
    "    end = '.csv'\n",
    "    main_path = 'D:/Michael D/Good PAG data/Final Fig Data/Sensory stim/'\n",
    "    df1 = pd.read_csv(main_path+'22June2_fish2G_rln_LeftWFBFavgs'+end, index_col=0)\n",
    "    df2 = pd.read_csv(main_path+'22June22_fish3_rln_LeftAllStimWFBFavgs'+end, index_col=0)\n",
    "    df3 = pd.read_csv(main_path+'23Mar22_fish2_rln_WFBFLeft_listavgs'+end, index_col=0)\n",
    "#     df4 = pd.read_csv(main_path+'22June2_fish2G_penk_LeftPAG6avgs'+end, index_col=0)\n",
    "#     df5 = pd.read_csv(main_path+'20July22_fish3_new_penkLeftAllStimclose_norespavgs'+end, index_col=0)\n",
    "#     df6 = pd.read_csv(main_path+'25May22_fish2_new_penkRightAllStimclose_norespavgs'+end, index_col=0)\n",
    "#     df7 = pd.read_csv(main_path+'25May22_fish3_new_penkLeftAllStimclose_norespavgs'+end, index_col=0)\n",
    "    tot_df = pd.concat((df1, df2, df3), axis=1)#, df4df5, df6, df7, df8, df5\n",
    "    tot_df.to_csv('Final_WFBFstim_rln_IpsAllStim.csv')\n",
    "    print(tot_df.shape)\n",
    "    plt.plot(tot_df)\n",
    "    plt.show()\n",
    "\n",
    "consol_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cond_averager():\n",
    "    \n",
    "    main_path = 'D:/Michael D/Good PAG data/final roi sets and activity/PAG6/PAG6windows/2535'\n",
    "\n",
    "    source_dir = Path(main_path)\n",
    "    files = source_dir.iterdir()\n",
    "    sides = ['Ips', 'Cont']\n",
    "    exps = ['rln', 'penk']\n",
    "#     rnr = ['resp']\n",
    "    x=0\n",
    "    for side in sides:\n",
    "        for exp in exps:\n",
    "            #Gets all files for a particular side and expression pattern\n",
    "            filenames = []\n",
    "            source_dir = Path(main_path)\n",
    "            files = source_dir.iterdir()\n",
    "            for item in files:\n",
    "                if side in str(item) and exp in str(item) and 'no' not in str(item):\n",
    "                    filenames.append(str(item).replace('\\\\','/'))\n",
    "            \n",
    "            print(filenames)\n",
    "            print()\n",
    "            \n",
    "\n",
    "cond_averager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #creates dict to cycle through animals\n",
    "# Mar2_f3 = ['A', 'B', 'C', 'D', 'E' ,'F', 'G', 'H', 'J']#, 'K', 'L', 'M', 'N']\n",
    "# mar9_f1 = ['A', 'B', 'C', 'D', 'E' ,'F', 'G', 'H', 'J', 'K', 'L']#, 'M', 'N']\n",
    "# May17_f2 = ['A', 'B', 'C', 'D', 'E' ,'F', 'G', 'H', 'J', 'K']#, 'L', 'M', 'N']\n",
    "# may25_f2 = ['A', 'B', 'C', 'D', 'E' ,'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N']\n",
    "# may25_f3 = ['A', 'B', 'C', 'D', 'E' ,'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N']\n",
    "# June1_f1 = ['A', 'B', 'C', 'D', 'E' ,'F', 'G', 'H', 'J', 'K', 'L', 'M']#, 'N']\n",
    "# July20_f3 = ['A', 'B', 'C', 'D', 'E' ,'F', 'G', 'H', 'J']#, 'K', 'L', 'M', 'N']\n",
    "# 'ABCDEFGHJKLMN'\n",
    "# 'ABCDEFGHJKLM'-1JUN\n",
    "# 'ABCDEFGHJ'-2MAR\n",
    "# 'ABCDEFGHJKL'-9MAR\n",
    "# 'ABCDEFGHJK'-17MAY\n",
    "# 'ABCDEFGHJ'-20JULY\n",
    "# 'ABCDEFGHJKLMN'-25MAY2\n",
    "# 'ABCDEFGHJKLMN'-25MAY3\n",
    "\n",
    "main_path = 'D:/Michael D/Good PAG data/final roi sets and activity/PAG6/orig_PAG6_activity/new/'\n",
    "sides = ['Ips', 'Cont']\n",
    "exps = ['rln', 'penk']\n",
    "for exp in exps:\n",
    "    for side in sides:\n",
    "        fname = '25May22_fish3_new_'+exp+side+'AllStim'\n",
    "#         fname = '2Mar22_fish3_new_'+exp+side+'AllStim'\n",
    "        tot_arr = pd.read_csv((main_path+fname+'.csv'), index_col=0)\n",
    "        trial_list = 'ABCDEFGHJKLMN'\n",
    "        resp_trials = 'ABCDEFGHJKLMN'\n",
    "        # noresp_trials = 'C'\n",
    "        ind_trial_length = int(tot_arr.shape[0]/len(trial_list))\n",
    "\n",
    "        avg_arr = [] \n",
    "        for trial in trial_list:\n",
    "            trial_f = tot_arr.iloc[(ind_trial_length*int(trial_list.index(trial))):(ind_trial_length*(int(trial_list.index(trial))+1))].reset_index().drop('index', axis=1)\n",
    "            avg_arr.append(trial_f)\n",
    "            \n",
    "        groupdf = pd.concat(avg_arr).mean(level=0)\n",
    "        print(groupdf.shape)\n",
    "        groupdf.to_csv(fname+'novavg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnr_averager(p_name, resp_trials, noresp_trials, all_trials, exp, side, full_path):\n",
    "    trial_list = all_trials\n",
    "    resp_trials = resp_trials\n",
    "    noresp_trials = noresp_trials\n",
    "#     cond_list = [pag6, dim3, dim4, dim2, wf, bf]\n",
    "    avg_list = [resp_trials, noresp_trials]\n",
    "    avg_name_list = ['resp_trials', 'noresp_trials']\n",
    "    \n",
    "    tot_arr = pd.read_csv((full_path), index_col=0)\n",
    "    ind_trial_length = int(tot_arr.shape[0]/len(all_trials))\n",
    "    print('#trials is', len(all_trials))\n",
    "    \n",
    "    for group, group_name in zip(avg_list, avg_name_list):\n",
    "        avg_arr = []\n",
    "        for trial in group:\n",
    "            trial_f = tot_arr.iloc[(ind_trial_length*int(trial_list.index(trial))):(ind_trial_length*(int(trial_list.index(trial))+1))].reset_index().drop('index', axis=1)\n",
    "            avg_arr.append(trial_f)\n",
    "        if len(group) == 1:\n",
    "            groupdf =  tot_arr.iloc[(ind_trial_length*int(trial_list.index(trial))):(ind_trial_length*(int(trial_list.index(trial))+1))].reset_index().drop('index', axis=1)\n",
    "            groupdf.to_csv(p_name+exp+side+group_name+'avgs.csv')\n",
    "            print(groupdf.shape)\n",
    "        else:\n",
    "            groupdf = pd.concat(avg_arr).mean(level=0)\n",
    "            print(groupdf.shape)\n",
    "            groupdf.to_csv(p_name+exp+side+group_name+'avgs.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell to concatenate averaged files\n",
    "\n",
    "main_path = 'D:/Michael D/Good PAG data/final roi sets and activity/PAG6/PAG6windows/2535/ind_avg_files/'\n",
    "sides = ['Ips', 'Cont']\n",
    "exps = ['rln', 'penk']\n",
    "rn = ['resp', 'noresp']\n",
    "\n",
    "for side in sides:\n",
    "    for rnr in rn:\n",
    "        exp='rln'\n",
    "\n",
    "        df1 = pd.read_csv(main_path+'1Jun22_fish1'+exp+side+rnr+'_trialsavgs.csv', index_col=0) \n",
    "        df2 = pd.read_csv(main_path+'2Mar22_fish3'+exp+side+rnr+'_trialsavgs.csv', index_col=0)\n",
    "        df3 = pd.read_csv(main_path+'9Mar22_fish1'+exp+side+rnr+'_trialsavgs.csv', index_col=0)\n",
    "        df4 = pd.read_csv(main_path+'17May22_fish2'+exp+side+rnr+'_trialsavgs.csv' , index_col=0)\n",
    "        df5 = pd.read_csv(main_path+'20July22_fish3'+exp+side+rnr+'_trialsavgs.csv' , index_col=0)\n",
    "        df6 = pd.read_csv(main_path+'25May22_fish2'+exp+side+rnr+'_trialsavgs.csv' , index_col=0)\n",
    "        df7 = pd.read_csv(main_path+'25May22_fish3'+exp+side+rnr+'_trialsavgs.csv' , index_col=0)\n",
    "\n",
    "        tot_df = pd.concat((df1, df2, df3, df4, df5,df6, df7), axis=1)#, df8, df5\n",
    "        tot_df.to_csv('Final_PAG6_'+exp+side+rnr+'2535AllStim.csv')\n",
    "        print(tot_df.shape)\n",
    "#     plt.plot(tot_df)\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = 'D:/Michael D/Good PAG data/final roi sets and activity/PAG6/PAG6windows/'\n",
    "sides = ['Ips', 'Cont']\n",
    "exps = ['rln', 'penk']\n",
    "for side in sides:\n",
    "    for exp in exps:\n",
    "        df1 = pd.read_csv(main_path+'Final_PAG6_'+exp+side+'AllStimBehnov.csv', index_col=0) \n",
    "        df2 = pd.read_csv(main_path+'Final_sens_PAG6_'+exp+side+'AllStim.csv', index_col=0)\n",
    "        tot_df = pd.concat((df1, df2), axis=1)#, df3, df4,df6, df7, df8, df5\n",
    "        tot_df.to_csv('Final_PAG6BehSensNov_'+exp+side+'AllStim.csv')\n",
    "        print(tot_df.shape, exp, side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organize for new window analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates dict to cycle through animals\n",
    "Mar2_f3 = ['A', 'B', 'C', 'D', 'E' ,'F', 'G', 'H', 'J']#, 'K', 'L', 'M', 'N'] 9\n",
    "mar9_f1 = ['A', 'B', 'C', 'D', 'E' ,'F', 'G', 'H', 'J', 'K', 'L']#, 'M', 'N'] 11\n",
    "May17_f2 = ['A', 'B', 'C', 'D', 'E' ,'F', 'G', 'H', 'J', 'K']#, 'L', 'M', 'N'] 10\n",
    "may25_f2 = ['A', 'B', 'C', 'D', 'E' ,'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N'] #13\n",
    "may25_f3 = ['A', 'B', 'C', 'D', 'E' ,'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N']#13\n",
    "June1_f1 = ['A', 'B', 'C', 'D', 'E' ,'F', 'G', 'H', 'J', 'K', 'L', 'M']#, 'N'] 12\n",
    "July20_f3 = ['A', 'B', 'C', 'D', 'E' ,'F', 'G', 'H', 'J']#, 'K', 'L', 'M', 'N'] 9\n",
    "\n",
    "\n",
    "\n",
    "neuro_trial_dict = {'9Mar22_fish1': mar9_f1, '25May22_fish2': may25_f2, '25May22_fish3': may25_f3, \n",
    "                   '2Mar22_fish3': Mar2_f3, '17May22_fish2': May17_f2, '1Jun22_fish1': June1_f1, '20July22_fish3': July20_f3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnr_averager(p_name, resp_trials, noresp_trials, all_trials, exp, side, full_path):\n",
    "    #creates average of response and no response and saves files\n",
    "\n",
    "    trial_list = all_trials\n",
    "    resp_trials = resp_trials\n",
    "    noresp_trials = noresp_trials\n",
    "    \n",
    "    if len(noresp_trials)==0:\n",
    "        noresp_trials=['A']\n",
    "\n",
    "\n",
    "#     cond_list = [pag6, dim3, dim4, dim2, wf, bf]\n",
    "    avg_list = [resp_trials, noresp_trials]\n",
    "    avg_name_list = ['resp_trials', 'noresp_trials']\n",
    "\n",
    "    \n",
    "    tot_arr = pd.read_csv((full_path), index_col=0)\n",
    "    ind_trial_length = int(tot_arr.shape[0]/len(all_trials))\n",
    "    print('#trials is', len(all_trials))\n",
    "    \n",
    "    for group, group_name in zip(avg_list, avg_name_list):\n",
    "        avg_arr = []\n",
    "        for trial in group:\n",
    "            trial_f = tot_arr.iloc[(ind_trial_length*int(trial_list.index(trial))):(ind_trial_length*(int(trial_list.index(trial))+1))].reset_index().drop('index', axis=1)\n",
    "            avg_arr.append(trial_f)\n",
    "        if len(group) == 1:\n",
    "            groupdf =  tot_arr.iloc[(ind_trial_length*int(trial_list.index(trial))):(ind_trial_length*(int(trial_list.index(trial))+1))].reset_index().drop('index', axis=1)\n",
    "            groupdf.to_csv(p_name+exp+side+group_name+'2037avgs.csv')\n",
    "            print(groupdf.shape)\n",
    "        else:\n",
    "            groupdf = pd.concat(avg_arr).mean(level=0)\n",
    "            print(groupdf.shape)\n",
    "            groupdf.to_csv(p_name+exp+side+group_name+'2037avgs.csv')\n",
    "        \n",
    "#     return groupdf\n",
    "        \n",
    "# groupdf = general_averager()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell which looks at behaviour to find if we get responses during the window\n",
    "\n",
    "main_path = 'D:/Michael D/Good PAG data/good_behaviours/PAG6_behaviours'\n",
    "\n",
    "source_dir = Path(main_path)\n",
    "files = source_dir.iterdir()\n",
    "tail_kin_files = []\n",
    "for item in files:\n",
    "    if 'tail-kinematics' in str(item):\n",
    "#     print(str(item).replace('\\\\','/'))\n",
    "        tail_kin_files.append(str(item).replace('\\\\','/'))\n",
    "\n",
    "def behaviour_check(open_window, close_window, trial):\n",
    "    test_file = pd.read_csv(trial)\n",
    "    tail_kin = test_file.loc[:,'Value.Amplitude']\n",
    "    \n",
    "    start_time = open_window*350\n",
    "    end_time = close_window*350\n",
    "    \n",
    "    \n",
    "#     if len(tail_kin[:start_time].loc[abs(tail_kin)>20]) > 5 :\n",
    "#         holder=0\n",
    "#     elif len(tail_kin[end_time:].loc[abs(tail_kin)>20]) > 5 :\n",
    "#         holder=0\n",
    "    if len(tail_kin[start_time:end_time].loc[abs(tail_kin)>20]) > 5 :\n",
    "        #determines if there was activity in the set window, if yes returns 1 in holder, if no returns 0\n",
    "#         print('activity')\n",
    "        holder = 1\n",
    "    else:\n",
    "#         print('NR')\n",
    "        holder = 0\n",
    "    return holder\n",
    "\n",
    "#provides list of len (behaviour_trials) where 0 is no behaviour, 1 is bheaviour\n",
    "tot = []\n",
    "for i in tail_kin_files:\n",
    "    holder = behaviour_check(20,37, i)\n",
    "    tot.append(holder)\n",
    "print(tot)\n",
    "\n",
    "#prints number of trials with behaviour and trial names\n",
    "com = 0\n",
    "h1 = []\n",
    "for i,j in zip(tot, tail_kin_files):\n",
    "    start = 59\n",
    "    if 'DATE' in j:\n",
    "        start+=30\n",
    "    if i == 1:\n",
    "        h1.append(j[start:-20])\n",
    "        com +=1\n",
    "        \n",
    "print(com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gets trials that match with behaviour\n",
    "fish_name_rnr = {}\n",
    "for fish in neuro_trial_dict.keys():\n",
    "    print(fish)\n",
    "    resp_list = []\n",
    "    noresp_list = []\n",
    "    neu_fish = fish[-1]\n",
    "    for h in h1:\n",
    "        beh_file = h\n",
    "        beh_fish = beh_file[-2]\n",
    "        beh_tri = beh_file[-1]\n",
    "        if fish[:5] in beh_file and beh_tri in neuro_trial_dict[fish] and beh_fish== neu_fish:\n",
    "            resp_list.append(beh_tri)\n",
    "#         elif fish[:5] in beh_file and beh_fish== neu_fish:\n",
    "#             print(fish[:5], beh_tri)\n",
    "# #             noresp_list.append(h[-1])\n",
    "    noresp_list = [f for f in neuro_trial_dict[fish] if f not in resp_list]\n",
    "    resp_trials =''.join(map(str, resp_list))\n",
    "    noresp_trials = ''.join(map(str, noresp_list))\n",
    "    fish_name_rnr[fish]={'resp': resp_trials, 'noresp': noresp_trials}\n",
    "#     print('resp trials are', resp_trials)\n",
    "#     print('noresp trials are', noresp_trials)\n",
    "#     no_resp = [f for f in neuro_trial_dict[i] if f not in resp_trials]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get ips/cont/ rln/penk neuro files\n",
    "\n",
    "main_path = 'D:/Michael D/Good PAG data/final roi sets and activity/PAG6/orig_PAG6_activity/new'\n",
    "\n",
    "source_dir = Path(main_path)\n",
    "files = source_dir.iterdir()\n",
    "sides = ['Ips', 'Cont']\n",
    "exps = ['rln', 'penk']\n",
    "x=0\n",
    "for side in sides:\n",
    "    for exp in exps:\n",
    "        #Gets all files for a particular side and expression pattern\n",
    "        filenames = []\n",
    "        source_dir = Path(main_path)\n",
    "        files = source_dir.iterdir()\n",
    "        for item in files:\n",
    "            if side in str(item) and exp in str(item):\n",
    "                filenames.append(str(item).replace('\\\\','/'))\n",
    "                \n",
    "        #purpose of this is to get just the one file that we are using for a side and an expression pattern, and \n",
    "                \n",
    "        for act_file in filenames:\n",
    "            for whole_fish in fish_name_rnr.keys():\n",
    "                for neu_name in fish_name_rnr:\n",
    "                            if whole_fish[:5] in neu_name and whole_fish[-5:] in neu_name and whole_fish[:5] in act_file and whole_fish[-5:] in act_file:\n",
    "#                                 print(neu_name, side, exp)\n",
    "                                resp_group = fish_name_rnr[neu_name]['resp']\n",
    "                                noresp_group = fish_name_rnr[neu_name]['noresp']\n",
    "                                all_stim = ''.join(sorted(list(resp_group+noresp_group)))\n",
    "                                rnr_averager(neu_name, resp_group, noresp_group, all_stim, exp, side, act_file)\n",
    "                                print(neu_name)\n",
    "\n",
    "        #Pass the response/no response trials for this particular fish\n",
    "        print()\n",
    "                                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doesn't actually do anything but prints names\n",
    "for whole_fish in fish_name_rnr.keys():\n",
    "    for neu_name in fish_name_rnr:\n",
    "        if whole_fish[:5] in neu_name and whole_fish[-5:] in neu_name:\n",
    "            print(neu_name)\n",
    "            for rnr in fish_name_rnr[neu_name].keys():\n",
    "                print('r/nr is', rnr, fish_name_rnr[neu_name][rnr])\n",
    "#     print(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #creates dict to cycle through animals\n",
    "# Mar2_f3 = ['A', 'B', 'C', 'D', 'E' ,'F', 'G', 'H', 'J']\n",
    "# mar9_f1 = ['A', 'B', 'C', 'D', 'E' ,'F', 'G', 'H', 'J', 'K', 'L']\n",
    "# May17_f2 = ['A', 'B', 'C', 'D', 'E' ,'F', 'G', 'H', 'J', 'K']\n",
    "# may25_f2 = ['A', 'B', 'C', 'D', 'E' ,'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N']\n",
    "# may25_f3 = ['A', 'B', 'C', 'D', 'E' ,'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N']\n",
    "# June1_f1 = ['A', 'B', 'C', 'D', 'E' ,'F', 'G', 'H', 'J', 'K', 'L', 'M']\n",
    "# July20_f3 = ['A', 'B', 'C', 'D', 'E' ,'F', 'G', 'H', 'J']\n",
    "# 'ABCDEFGHJKLMN'\n",
    "# 'ABCDEFGHJKLM'-1JUN\n",
    "# 'ABCDEFGHJ'-2MAR\n",
    "# 'ABCDEFGHJKL'-9MAR\n",
    "# 'ABCDEFGHJK'-17MAY\n",
    "# 'ABCDEFGHJ'-20JULY\n",
    "# 'ABCDEFGHJKLMN'-25MAY2\n",
    "# 'ABCDEFGHJKLMN'-25MAY3\n",
    "\n",
    "\n",
    "\n",
    "main_path = 'D:/Michael D/Good PAG data/final roi sets and activity/PAG6/orig_PAG6_activity/new/'\n",
    "sides = ['Ips', 'Cont']\n",
    "exps = ['rln', 'penk']\n",
    "for exp in exps:\n",
    "    for side in sides:\n",
    "        fname = '25May22_fish3_new_'+exp+side+'AllStim'\n",
    "#         fname = '2Mar22_fish3_new_'+exp+side+'AllStim'\n",
    "        tot_arr = pd.read_csv((main_path+fname+'.csv'), index_col=0)\n",
    "        trial_list = 'ABCDEFGHJKLMN'\n",
    "        resp_trials = 'ABCDEFGHJKLMN'\n",
    "        # noresp_trials = 'C'\n",
    "        ind_trial_length = int(tot_arr.shape[0]/len(trial_list))\n",
    "\n",
    "        avg_arr = [] \n",
    "        for trial in trial_list:\n",
    "            trial_f = tot_arr.iloc[(ind_trial_length*int(trial_list.index(trial))):(ind_trial_length*(int(trial_list.index(trial))+1))].reset_index().drop('index', axis=1)\n",
    "            avg_arr.append(trial_f)\n",
    "            \n",
    "        groupdf = pd.concat(avg_arr).mean(level=0)\n",
    "        print(groupdf.shape)\n",
    "        groupdf.to_csv(fname+'novavg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell to concatenate averaged files\n",
    "\n",
    "main_path = 'D:/Michael D/Good PAG data/final roi sets and activity/PAG6/PAG6windows/2535/ind_avg_files/'\n",
    "sides = ['Ips', 'Cont']\n",
    "exps = ['rln', 'penk']\n",
    "rn = ['resp', 'noresp']\n",
    "tw='2535'\n",
    "\n",
    "for side in sides:\n",
    "    for rnr in rn:\n",
    "        exp='penk'\n",
    "        df1 = pd.read_csv(main_path+'1Jun22_fish1'+exp+side+rnr+'_trialsavgs.csv', index_col=0) \n",
    "        df2 = pd.read_csv(main_path+'2Mar22_fish3'+exp+side+rnr+'_trialsavgs.csv', index_col=0)\n",
    "        df3 = pd.read_csv(main_path+'9Mar22_fish1'+exp+side+rnr+'_trialsavgs.csv', index_col=0)\n",
    "#         df4 = pd.read_csv(main_path+'17May22_fish2'+exp+side+rnr+'_trials'+tw+'avgs.csv' , index_col=0)\n",
    "        df5 = pd.read_csv(main_path+'20July22_fish3'+exp+side+rnr+'_trialsavgs.csv' , index_col=0)\n",
    "        df6 = pd.read_csv(main_path+'25May22_fish2'+exp+side+rnr+'_trialsavgs.csv' , index_col=0)\n",
    "        df7 = pd.read_csv(main_path+'25May22_fish3'+exp+side+rnr+'_trialsavgs.csv' , index_col=0)\n",
    "#         df1 = pd.read_csv(main_path+'1Jun22_fish1'+exp+side+rnr+'_trials'+tw+'avgs.csv', index_col=0) \n",
    "#         df2 = pd.read_csv(main_path+'2Mar22_fish3'+exp+side+rnr+'_trials'+tw+'avgs.csv', index_col=0)\n",
    "#         df3 = pd.read_csv(main_path+'9Mar22_fish1'+exp+side+rnr+'_trials'+tw+'avgs.csv', index_col=0)\n",
    "# #         df4 = pd.read_csv(main_path+'17May22_fish2'+exp+side+rnr+'_trials'+tw+'avgs.csv' , index_col=0)\n",
    "#         df5 = pd.read_csv(main_path+'20July22_fish3'+exp+side+rnr+'_trials'+tw+'avgs.csv' , index_col=0)\n",
    "#         df6 = pd.read_csv(main_path+'25May22_fish2'+exp+side+rnr+'_trials'+tw+'avgs.csv' , index_col=0)\n",
    "#         df7 = pd.read_csv(main_path+'25May22_fish3'+exp+side+rnr+'_trials'+tw+'avgs.csv' , index_col=0)\n",
    "\n",
    "        tot_df = pd.concat((df1, df2, df3, df5,df6, df7), axis=1)#, df8, df5\n",
    "#         Final_2535resp_rln_IpsAllStim\n",
    "#         tot_df.to_csv('Final_PAG6_'+exp+side+rnr+tw+'AllStim.csv')\n",
    "        tot_df.to_csv('Final_'+tw+rnr+'_'+exp+'_'+side+'AllStim.csv')\n",
    "        print(tot_df.shape)\n",
    "#     plt.plot(tot_df)\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
